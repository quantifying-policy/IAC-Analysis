{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3a. Topic Modelling\n",
    "In this notebook I implement a ML model for topic modelling. The abstracts cover a wide range of technical and policy-relevant topics. The goal of topic modelling is to classify the abstract into different topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oeB7xgNaXYg7"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fzPp-HdUWCI2"
   },
   "outputs": [],
   "source": [
    "### There was some issue with __init__() got an unexpected keyword argument 'cachedir' when importing top2vec. Using an older version of joblib (1.1.0) avoids this problem,\n",
    "### but I should undo this asap top2vec works on the latest versions of joblib and hdbscan\n",
    "### in this order: pip install top2vec, pip install upgrade joblib, import top2vec\n",
    "!pip install top2vec\n",
    "!pip install --upgrade joblib==1.1.0\n",
    "from top2vec import Top2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IigtHbhrXjAn"
   },
   "source": [
    "## 1. Importing Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 334,
     "status": "ok",
     "timestamp": 1667661523456,
     "user": {
      "displayName": "Daniel Leichte",
      "userId": "15787498902779762448"
     },
     "user_tz": -60
    },
    "id": "ALDG5mWWXmw4"
   },
   "outputs": [],
   "source": [
    "###unpickling\n",
    "directory = \"/content/drive/MyDrive/Colab Notebooks/ESPI_Codes/IAC_Analysis/1.HTML_Parsing/\"\n",
    "with open(directory+\"IAC_raw_data.pickle\", \"rb\") as handle:\n",
    "  dict_of_info = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQt1JQhjXmWv"
   },
   "source": [
    "## 2. Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4RmuEmPfBSQ"
   },
   "source": [
    "These are the abstracts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kd4TOSYJZuVG"
   },
   "outputs": [],
   "source": [
    "abstracts_raw = {}\n",
    "for key, value in dict_of_info.items():\n",
    "  abstracts_raw.update({key:[]})\n",
    "  for year, paper_ids in value.items():\n",
    "    abstracts_raw[key].append(paper_ids[\"abstract\"].lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eahd3x8UReoT"
   },
   "source": [
    "This dictionary contains as keys the top2vec id and as value the paper_id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1667661548135,
     "user": {
      "displayName": "Daniel Leichte",
      "userId": "15787498902779762448"
     },
     "user_tz": -60
    },
    "id": "2uW2Sft_X4o1"
   },
   "outputs": [],
   "source": [
    "top2vec_paper_id_dict = {}\n",
    "for key, value in dict_of_info.items():\n",
    "  for count, paper_id in enumerate(value):\n",
    "    top2vec_paper_id_dict.update({paper_id: str(key)+\"_\"+str(count)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emFoThYmWeLP"
   },
   "source": [
    "Top2vec requires one input: the documents as a list of strings (here: docs).\n",
    "In addition to this, I will provide a custom list of ids for the docs. Each id will have at the beginning the year, so that we can later distinguish the docs by year and see how the topics change over the 5 year period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36gygQPaWYsm"
   },
   "outputs": [],
   "source": [
    "docs = []\n",
    "ids = []\n",
    "for key, value in abstracts_raw.items():\n",
    "  for count, abstract in enumerate(value):\n",
    "    docs.append(abstract)\n",
    "    ids.append(str(key)+\"_\"+str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_la1-3rXRkX"
   },
   "source": [
    "## 3. Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8M9SZ7DVXTkH"
   },
   "outputs": [],
   "source": [
    "### training the model\n",
    "#model1 = Top2Vec(documents = docs, document_ids = ids, ngram_vocab = True, speed= \"deep-learn\", verbose=True)\n",
    "#model1.save(\"IAC_top2vec_model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFmHrTs5XWep"
   },
   "outputs": [],
   "source": [
    "### loading the model\n",
    "directory = \"/content/drive/MyDrive/Colab Notebooks/ESPI_Codes/IAC_Analysis/3.Topic_Modeling/\"\n",
    "model1 = Top2Vec.load(directory+\"3a.IAC_top2vec_model1\")\n",
    "\n",
    "### loading the topic names from a dict I created\n",
    "topic_names_model1 = json.load(open(directory+\"3ai.topic_names.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duSCYCkOWhbK"
   },
   "source": [
    "#4. Functions for interpreting the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fsa3cFXNWn9z"
   },
   "source": [
    "This function prints the basic information about a model: number of topics, for each topic the topic number and the size (i.e., number of docs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZPFu1AnXWmMB"
   },
   "outputs": [],
   "source": [
    "def basic_info(model):\n",
    "  topic_sizes, topic_nums = model.get_topic_sizes()\n",
    "  print(f\"This model has {model.get_num_topics()} topics\")\n",
    "  print(3*\"_________\")\n",
    "  for topic_size, topic_num in zip(topic_sizes, topic_nums):\n",
    "    print(f\"Topic #{topic_num} is size: {topic_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YyaGNwP7WtT_"
   },
   "source": [
    "This function prints all the topics and associated top-words that define the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D1eRlQwIWtkh"
   },
   "outputs": [],
   "source": [
    "def topic_words(model, num_of_topics):\n",
    "  all = model.get_num_topics()\n",
    "  topic_words, word_scores, topic_nums = model.get_topics(num_of_topics)\n",
    "  for words, scores, nums in zip(topic_words, word_scores, topic_nums):\n",
    "    print(nums)\n",
    "    print(f\"Words:{words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gwj_mvJPWwSO"
   },
   "source": [
    "This function prints a word cloud for the specified topic number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q7ylyfvpWwh2"
   },
   "outputs": [],
   "source": [
    "def word_clouds(model, list_of_topics):\n",
    "  for element in list_of_topics:\n",
    "    model1.generate_topic_wordcloud(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFNXQ7PFWyDp"
   },
   "source": [
    "This function prints the document associated with a topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dlM2ui30W09E"
   },
   "outputs": [],
   "source": [
    "def docs_by_topic(model, topic_num, num_docs):\n",
    "  documents, document_scores, document_ids = model.search_documents_by_topic(topic_num= topic_num, num_docs=num_docs)\n",
    "  for doc, score, doc_id in zip(documents, document_scores, document_ids):\n",
    "    print(f\"Document: {doc_id}, Score: {score}\")\n",
    "    print(\"-----------\")\n",
    "    print(doc)\n",
    "    print(\"-----------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCZQVPLbW2sr"
   },
   "source": [
    "This function prints similar words of a list of keywords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l4nHD4AnW402"
   },
   "outputs": [],
   "source": [
    "def keyword_search(model, keywords):\n",
    "  words, word_scores = model.similar_words(keywords=keywords, keywords_neg=[], num_words=20)\n",
    "  for word, score in zip(words, word_scores):\n",
    "    print(f\"{word} {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "470fP9NSW6El"
   },
   "source": [
    "This function shows how many docs are associated with a topic over the 5 years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYSg1WtWW8kl"
   },
   "outputs": [],
   "source": [
    "def topics_per_year(model):\n",
    "  result = {}\n",
    "  for topic_number in model.get_topics()[2]:\n",
    "    result.update({topic_number: {'Words': [],\n",
    "                                  'Total': [],\n",
    "                                  '2018': 0,\n",
    "                                  '2019': 0,\n",
    "                                  '2020': 0,\n",
    "                                  '2021': 0,\n",
    "                                  '2022': 0}})\n",
    "    \n",
    "    topic_size = model.get_topic_sizes()[0][topic_number] #number of docs in a topic\n",
    "    list_of_words = model.get_topics()[0][topic_number] #words that make up a topic\n",
    "    result[topic_number].update({\"Words\": list_of_words,\n",
    "                                 \"Total\": topic_size})\n",
    "\n",
    "    list_of_doc_ids = model.search_documents_by_topic(topic_num = topic_number, num_docs = topic_size)[2]\n",
    "    for doc_id in list_of_doc_ids:\n",
    "      result[topic_number][doc_id[:4]] +=1\n",
    "      \n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5silP7vf_g_"
   },
   "source": [
    "## 5. Exporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtkwiCWJiW30"
   },
   "source": [
    "This is a simplified dict with top2vec ids as key and a nested dict with topic number and name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qK2aDd1YgFD8"
   },
   "outputs": [],
   "source": [
    "output = {}\n",
    "for topic in model1.get_topic_sizes()[1]:\n",
    "  topic_size = model1.get_topic_sizes()[0][topic]\n",
    "  list_of_docs = model1.search_documents_by_topic(topic_num = topic, num_docs = topic_size)[2]\n",
    "  for doc in list_of_docs:\n",
    "    output.update({doc: {\"topic number\": topic, \"topic name\": topic_names_model1[str(topic)]}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1667661583385,
     "user": {
      "displayName": "Daniel Leichte",
      "userId": "15787498902779762448"
     },
     "user_tz": -60
    },
    "id": "Z8GLs0M1g_9F"
   },
   "outputs": [],
   "source": [
    "### pickling\n",
    "with open(\"3a.doc_topic_name_number.pickle\", \"wb\") as f:\n",
    "  pickle.dump(output, f, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#the top2vec_id and paper_id dictionary:\n",
    "with open(\"3a.top2vec_paper_id_dict.pickle\", \"wb\") as f:\n",
    "  pickle.dump(top2vec_paper_id_dict, f, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Conclusion\n",
    "Now, all abstracts are categorised into one of ca. 100 distinct topics. The topics do not have names yet - they are represented by an index. In 3b. I'll give the topics a more meaningful name. In step 4, I'll consolidate the topics and the new features from step 3 (pre-processing), namely organisation type, to create one datastructure that contains all the relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOPnRd/crczQNLCSG/kX3AF",
   "collapsed_sections": [],
   "mount_file_id": "1zUS3ssD8Nf5_0ge280qtm7uE7Lq5lpnV",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
